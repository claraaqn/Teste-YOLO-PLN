{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -i INPUT\n",
      "ipykernel_launcher.py: error: the following arguments are required: -i/--input\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mclar\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "# constantes do modelo\n",
    "CONFIDENCE_MIN = 0.4\n",
    "NMS_THRESHOLD = 0.2\n",
    "MODEL_BASE_PATH = \"yolo-coco\"\n",
    "\n",
    "# receber os argumentos para o script\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--input\", required=True, help=\"Endereço do streaming do drone\")\n",
    "streaming_path = vars(ap.parse_args())['input']\n",
    "\n",
    "# extrair os nomes das classes a partir do arquivo\n",
    "print(\"[+] Carregando labels das classes treinadas...\")\n",
    "with open(os.path.sep.join([MODEL_BASE_PATH, 'coco.names'])) as f:\n",
    "    labels = f.read().strip().split(\"\\n\")\n",
    "\n",
    "    # gerar cores únicas para cada label\n",
    "    np.random.seed(42)\n",
    "    colors = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")\n",
    "\n",
    "# carregar o modelo treinado YOLO (c/ COCO dataset)\n",
    "print(\"[+] Carregando o modelo YOLO treinado no COCO dataset...\")\n",
    "net = cv2.dnn.readNetFromDarknet(\n",
    "    os.path.sep.join([MODEL_BASE_PATH, 'yolov3.cfg']),\n",
    "    os.path.sep.join([MODEL_BASE_PATH, 'yolov3.weights']))\n",
    "\n",
    "# extrair layers não conectados da arquitetura YOLO\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "vs = cv2.VideoCapture(0).start()\n",
    "time.sleep(1)\n",
    "fps = FPS().start()\n",
    "print(\"[+] Iniciando a recepção do streaming via RTMP...\")\n",
    "\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "\n",
    "    # caso se deseje redimensionar os frames\n",
    "    frame = cv2.resize(frame, None, fx=0.2, fy=0.2)\n",
    "\n",
    "    # capturar a largura e altura do frame\n",
    "    (H, W) = frame.shape[:2]\n",
    "\n",
    "    # construir um container blob e fazer uma passagem (forward) na YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layer_outputs = net.forward(ln)\n",
    "\n",
    "    # criar listas com boxes, nível de confiança e ids das classes\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            # filtrar pelo threshold da confiança\n",
    "            if confidence > CONFIDENCE_MIN and class_id in [0, 1, 2, 3]:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (center_x, center_y, width, height) = box.astype(\"int\")\n",
    "\n",
    "                x = int(center_x - (width / 2))\n",
    "                y = int(center_y - (height / 2))\n",
    "\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # eliminar ruído e redundâncias aplicando non-maxima suppression\n",
    "    new_ids = cv2.dnn.NMSBoxes(boxes, confidences,CONFIDENCE_MIN, NMS_THRESHOLD)\n",
    "    if len(new_ids) > 0:\n",
    "        for i in new_ids.flatten():\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "            # plotar retângulo e texto das classes detectadas no frame atual\n",
    "            color_picked = [int(c) for c in colors[class_ids[i]]]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color_picked, 2)\n",
    "            text = \"{}: {:.4f}\".format(labels[class_ids[i]], confidences[i])\n",
    "            cv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_picked, 2)\n",
    "\n",
    "    # exibir o frame atual\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # sair, caso seja pressionada a tecla ESC\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "\n",
    "    # atualiza o fps\n",
    "    fps.update()\n",
    "\n",
    "\n",
    "\n",
    "# eliminar processos e janelas\n",
    "fps.stop()\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
